{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c5f3cb6-fe29-48e2-b105-6064cf48730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov Decision Process: \n",
      "\n",
      "a = U, s' = 0, s = 2, r = 0\n",
      "a = U, s' = 1, s = 3, r = 2\n",
      "a = U, s' = 2, s = 2, r = 0\n",
      "a = U, s' = 3, s = 3, r = 2\n",
      "a = D, s' = 0, s = 0, r = 0\n",
      "a = D, s' = 1, s = 1, r = 0\n",
      "a = D, s' = 2, s = 0, r = 0\n",
      "a = D, s' = 3, s = 1, r = 0\n",
      "a = R, s' = 0, s = 1, r = 0\n",
      "a = R, s' = 1, s = 1, r = 0\n",
      "a = R, s' = 2, s = 3, r = 2\n",
      "a = R, s' = 3, s = 3, r = 2\n",
      "a = L, s' = 0, s = 0, r = 0\n",
      "a = L, s' = 1, s = 0, r = 0\n",
      "a = L, s' = 2, s = 2, r = 0\n",
      "a = L, s' = 3, s = 2, r = 0\n"
     ]
    }
   ],
   "source": [
    "actions = ['U', 'D', 'R', 'L']\n",
    "states = [0, 1, 2, 3]\n",
    "\n",
    "# Dimensions : [ A x S x 2 ]\n",
    "\n",
    "MDP = [[[2, 0], [3, 2], [2, 0], [3, 2]],\n",
    "       [[0, 0], [1, 0], [0, 0], [1, 0]],\n",
    "       [[1, 0], [1, 0], [3, 2], [3, 2]],\n",
    "       [[0, 0], [0, 0], [2, 0], [2, 0]]]\n",
    "\n",
    "print(f'Markov Decision Process: \\n')\n",
    "for r, a in enumerate(MDP):\n",
    "    for c, s in enumerate(a):\n",
    "        print(f\"a = {actions[r]}, s' = {c}, s = {s[0]}, r = {s[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8704f607-f6e0-49c7-b9f8-7cbdcbe7328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Random Policy: \n",
      "\n",
      "s = 0, a = U, p = 0.25\n",
      "s = 0, a = D, p = 0.25\n",
      "s = 0, a = R, p = 0.25\n",
      "s = 0, a = L, p = 0.25\n",
      "s = 1, a = U, p = 0.25\n",
      "s = 1, a = D, p = 0.25\n",
      "s = 1, a = R, p = 0.25\n",
      "s = 1, a = L, p = 0.25\n",
      "s = 2, a = U, p = 0.25\n",
      "s = 2, a = D, p = 0.25\n",
      "s = 2, a = R, p = 0.25\n",
      "s = 2, a = L, p = 0.25\n",
      "s = 3, a = U, p = 0.25\n",
      "s = 3, a = D, p = 0.25\n",
      "s = 3, a = R, p = 0.25\n",
      "s = 3, a = L, p = 0.25\n"
     ]
    }
   ],
   "source": [
    "# Dimension : [ A x S ]\n",
    "\n",
    "pi = [[0.25, 0.25, 0.25, 0.25],\n",
    "      [0.25, 0.25, 0.25, 0.25],\n",
    "      [0.25, 0.25, 0.25, 0.25],\n",
    "      [0.25, 0.25, 0.25, 0.25]]\n",
    "\n",
    "print(f'Equal Random Policy: \\n')\n",
    "for r, s in enumerate(pi):\n",
    "    for c, a in enumerate(s):\n",
    "        print(f's = {r}, a = {actions[c]}, p = {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9f18b08-4e4e-4d8d-bf33-1c72241febb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration: 0, total reward: 0\n",
      "current iteration: 10, total reward: 12\n",
      "current iteration: 20, total reward: 18\n",
      "current iteration: 30, total reward: 28\n",
      "current iteration: 40, total reward: 36\n",
      "current iteration: 50, total reward: 36\n",
      "current iteration: 60, total reward: 46\n",
      "current iteration: 70, total reward: 52\n",
      "current iteration: 80, total reward: 60\n",
      "current iteration: 90, total reward: 66\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "current_state = 0\n",
    "total_reward_pi = 0\n",
    "ITERATIONS = 100\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    \n",
    "    action = np.random.choice(len(pi[current_state]), p=pi[current_state])\n",
    "\n",
    "    new_state, reward = MDP[action][current_state][0], MDP[action][current_state][1]\n",
    "\n",
    "    total_reward_pi += reward\n",
    "\n",
    "    current_state = new_state\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'current iteration: {i}, total reward: {total_reward_pi}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23c948c8-5245-4486-9126-bb3020f804f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Random Policy: \n",
      "\n",
      "s = 0, a = U, p = 0.4\n",
      "s = 0, a = D, p = 0.1\n",
      "s = 0, a = R, p = 0.4\n",
      "s = 0, a = L, p = 0.1\n",
      "s = 1, a = U, p = 0.7\n",
      "s = 1, a = D, p = 0.1\n",
      "s = 1, a = R, p = 0.1\n",
      "s = 1, a = L, p = 0.1\n",
      "s = 2, a = U, p = 0.1\n",
      "s = 2, a = D, p = 0.1\n",
      "s = 2, a = R, p = 0.7\n",
      "s = 2, a = L, p = 0.1\n",
      "s = 3, a = U, p = 0.4\n",
      "s = 3, a = D, p = 0.1\n",
      "s = 3, a = R, p = 0.4\n",
      "s = 3, a = L, p = 0.1\n"
     ]
    }
   ],
   "source": [
    "# Dimension : [ A x S ]\n",
    "\n",
    "better_pi = [[0.4, 0.1, 0.4, 0.1],\n",
    "             [0.7, 0.1, 0.1, 0.1],\n",
    "             [0.1, 0.1, 0.7, 0.1],\n",
    "             [0.4, 0.1, 0.4, 0.1]]\n",
    "\n",
    "print(f'Equal Random Policy: \\n')\n",
    "for r, s in enumerate(better_pi):\n",
    "    for c, a in enumerate(s):\n",
    "        print(f's = {r}, a = {actions[c]}, p = {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c1b619d-b43a-4f41-bb4f-16e3513e1dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration: 0, total reward: 0\n",
      "current iteration: 10, total reward: 8\n",
      "current iteration: 20, total reward: 20\n",
      "current iteration: 30, total reward: 36\n",
      "current iteration: 40, total reward: 56\n",
      "current iteration: 50, total reward: 70\n",
      "current iteration: 60, total reward: 80\n",
      "current iteration: 70, total reward: 98\n",
      "current iteration: 80, total reward: 114\n",
      "current iteration: 90, total reward: 124\n"
     ]
    }
   ],
   "source": [
    "current_state = 0\n",
    "total_reward_better_pi = 0\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    \n",
    "    action = np.random.choice(len(better_pi[current_state]), p=better_pi[current_state])\n",
    "\n",
    "    new_state, reward = MDP[action][current_state][0], MDP[action][current_state][1]\n",
    "\n",
    "    total_reward_better_pi += reward\n",
    "\n",
    "    current_state = new_state\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'current iteration: {i}, total reward: {total_reward_better_pi}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
