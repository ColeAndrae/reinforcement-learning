{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943cc84a-46bf-4f7e-82bf-a7fb81f7a0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 50000/50000 [08:16<00:00, 100.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] : [-25.21883    -6.7714643  -1.5462     -1.5759706]\n",
      "[0, 1] : [-23.631535    -5.2926893    2.9914434   -0.34147358]\n",
      "[0, 2] : [-20.760471   -2.2748976   8.815998    2.2772093]\n",
      "[0, 3] : [-17.889347    0.7428942  14.640705    4.89577  ]\n",
      "[0, 4] : [-15.018223    3.7607164  20.465351    7.514453 ]\n",
      "[1, 0] : [-8.867632   1.451786   3.8933213  2.5733118]\n",
      "[1, 1] : [-5.961247  -1.9237776  2.1070516  2.2133741]\n",
      "[1, 2] : [-2.1608167 -1.0956373  6.9642215  3.4717436]\n",
      "[1, 3] : [ 4.240108   2.8499498 14.428272   7.5338926]\n",
      "[1, 4] : [10.371487   6.8539476 21.626942  11.274646 ]\n",
      "[2, 0] : [-9.817783  -6.549306   2.292652   1.9081602]\n",
      "[2, 1] : [-0.6704143 -0.1258831  7.36745    6.072482 ]\n",
      "[2, 2] : [-1.1276134   0.36771584  3.392986   -0.6708574 ]\n",
      "[2, 3] : [4.3242984 4.8848467 5.965465  2.7529707]\n",
      "[2, 4] : [12.599651  3.555089 16.271397 12.228259]\n",
      "[3, 0] : [-10.547428  -13.462546    0.9356267   1.325366 ]\n",
      "[3, 1] : [-1.4000896 -7.0391245  6.0104403  5.489665 ]\n",
      "[3, 2] : [ 7.7472453  -0.61570644 11.085228    9.653966  ]\n",
      "[3, 3] : [-15.336249   -5.2615757 -15.114267  -25.412651 ]\n",
      "[3, 4] : [86.68864  95.10308  86.879944 86.344986]\n",
      "[4, 0] : [-11.277103  -20.37579    -0.4213603   0.7425871]\n",
      "[4, 1] : [ -2.1297688 -13.95237     4.653396    4.906848 ]\n",
      "[4, 2] : [25.819515 -9.677763 29.232822 33.200344]\n",
      "[4, 3] : [ 84.34957   -9.12005   85.769325 101.07206 ]\n",
      "[4, 4] : [ 0.16744576 -8.616542    0.14650317 -6.936536  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)\n",
    "        self.out = nn.Linear(16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.out(x)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epsilon = 0.1\n",
    "gamma = 0.9\n",
    "episodes = 50000\n",
    "\n",
    "WIDTH, HEIGHT = 5, 5\n",
    "states = np.arange(0, WIDTH * HEIGHT)\n",
    "states.resize(WIDTH, HEIGHT)\n",
    "\n",
    "r = np.zeros(WIDTH * HEIGHT)\n",
    "r.resize(WIDTH, HEIGHT)\n",
    "r[WIDTH - 1][HEIGHT - 1] = 10\n",
    "\n",
    "start_state = 0\n",
    "end_state = WIDTH * HEIGHT - 1\n",
    "\n",
    "actions = ['U', 'D', 'L', 'R']\n",
    "\n",
    "def in_bounds(current_state):\n",
    "    return 0 <= current_state <= end_state\n",
    "\n",
    "def get_q(state):\n",
    "    state_tensor = torch.tensor([[state // WIDTH, state % WIDTH]], dtype=torch.float32)\n",
    "    return model(state_tensor).squeeze()\n",
    "\n",
    "def select_action(state):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.random.randint(4)\n",
    "    else:\n",
    "        return get_q(state).argmax().item()\n",
    "\n",
    "def agent_step(state, action):\n",
    "\n",
    "    if actions[action] == 'U':\n",
    "        next_state = state - WIDTH\n",
    "    elif actions[action] == 'D':\n",
    "        next_state = state + WIDTH\n",
    "    elif actions[action] == 'L':\n",
    "        next_state = state - 1\n",
    "    elif actions[action] == 'R':\n",
    "        next_state = state + 1\n",
    "    \n",
    "    if in_bounds(next_state):\n",
    "        td_target = torch.tensor(r[next_state // WIDTH][next_state % WIDTH] + gamma * get_q(state).max().item(), dtype=torch.float32)\n",
    "    elif next_state == end_state:\n",
    "        td_target = torch.tensor(r[next_state // WIDTH][next_state % WIDTH], dtype=torch.float32)\n",
    "    else:\n",
    "        td_target =  torch.tensor(-10, dtype=torch.float32)\n",
    "    \n",
    "    q_values = get_q(state)\n",
    "    current_q = q_values[action]\n",
    "\n",
    "    loss = loss_fn(current_q, td_target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    next_action = select_action(next_state)\n",
    "    return next_state, next_action\n",
    "\n",
    "for episode in tqdm(range(episodes)):\n",
    "\n",
    "    current_state = start_state\n",
    "    current_action = select_action(current_state)\n",
    "\n",
    "    while in_bounds(current_state):\n",
    "    \n",
    "        current_state, current_action = agent_step(current_state, current_action)\n",
    "\n",
    "for row in range(WIDTH):\n",
    "    for col in range(HEIGHT):\n",
    "        with torch.no_grad():\n",
    "            print(f'[{row}, {col}] : {model(torch.tensor([row, col], dtype=torch.float32)).numpy()}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7410ff22-b88a-45b5-83f0-56edf2e5d59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "6\n",
      "11\n",
      "12\n",
      "13\n",
      "18\n",
      "19\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "18\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "current_state = 0\n",
    "\n",
    "while current_state != end_state:\n",
    "\n",
    "    print(current_state)\n",
    "\n",
    "    temp_state = current_state\n",
    "    \n",
    "    current_state, current_action = agent_step(current_state, current_action)\n",
    "\n",
    "    if actions[current_action] == 'U':\n",
    "        current_state = temp_state - WIDTH\n",
    "    elif actions[current_action] == 'D':\n",
    "        current_state = temp_state + WIDTH\n",
    "    elif actions[current_action] == 'L':\n",
    "        current_state = temp_state - 1\n",
    "    elif actions[current_action] == 'R':\n",
    "        current_state = temp_state + 1\n",
    "\n",
    "    if not in_bounds(current_state):\n",
    "        current_state = 0\n",
    "\n",
    "print(current_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bc5d3-c53e-4181-8aec-c0290ef7490c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
